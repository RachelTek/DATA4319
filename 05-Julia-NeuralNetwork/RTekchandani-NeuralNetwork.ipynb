{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rachel Tekchandani DATA 4319\n",
    "\n",
    "## Neural Network from Scratch in Julia using the MNIST Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets    # give us access to MNIST data set\n",
    "using Images        # allow us to view images\n",
    "using TestImages\n",
    "using Plots         # plot performance and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is 70,000 images of hard written digits.  \n",
    "### We will use 60,000 for training and the remaining 10,000 will be used for testing.\n",
    "\n",
    "Dataset: THE MNIST DATABASE of handwritten digits\n",
    "Authors: Yann LeCun, Corinna Cortes, Christopher J.C. Burges\n",
    "Website: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "[LeCun et al., 1998a]\n",
    "\n",
    "\n",
    "    Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.\n",
    "    \"Gradient-based learning applied to document recognition.\"\n",
    "    Proceedings of the IEEE, 86(11):2278-2324, November 1998\n",
    "    \n",
    "![mnist](mnist.png)\n",
    "\n",
    "## MNIST = Modified National Institute of Standards and Technology database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "...\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8], [5, 0, 4, 1, 9, 2, 1, 3, 1, 4  …  9, 2, 9, 5, 1, 8, 3, 5, 6, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the training data set\n",
    "train_x, train_y = MNIST.traindata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "...\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8]\n",
       "\n",
       "Normed{UInt8,8}[0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; … ; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8; 0.0N0f8 0.0N0f8 … 0.0N0f8 0.0N0f8], [7, 2, 1, 0, 4, 1, 4, 9, 5, 9  …  7, 8, 9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the testing data set\n",
    "test_x, test_y = MNIST.testdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors are multi dimensionar array.  each slice is a matrix, each matrix is a feature of an image\n",
    "\n",
    "## check size of train_x\n",
    "\n",
    "![tensor](tensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 60000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28 pixels wide, 28 pixels tall and 60,000 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28 Array{N0f8,2} with eltype Normed{UInt8,8}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.216  0.533  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.675  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.071  0.886  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.671  0.992  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.118     0.859  0.992  0.831  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.141     0.992  0.992  0.529  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.369  …  0.992  0.992  0.518  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.604     0.992  0.957  0.063  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.012  0.667     0.992  0.522  0.0    0.0  0.0  0.0\n",
       " ⋮                        ⋮             ⋱                       ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0  0.494  0.992     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.533  0.992     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.686  0.882     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.102  0.675     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.651  0.992  …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0    0.949     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.969  0.765     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.498  0.251     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempt to visualize the data\n",
    "train_x[:, :,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIKSURBVGje7dpPiI1RGMfxzyAL8qfZmFISi1EiFigpSZJiMbGhbLBDVjZ2FqSwQBazUhayxYryd6FuTf5syN6fHYM0yGDxvJPr3tu9c2eKc0/nW29v5z3ve3/93qdz3uc551IoFAqFQqHQ+/R1+8BMLKhrH8EcDOIwzmEvvuIMTjY8P+NfO8xfcFanG5ZgNjZiExZid4v7XuMihvAZz/EwBYf5C7Ydh2tx19/jrhU/cQBfqvZbfMCrFBzmL9g2hv2oYVmLvhpGsQXfdY7zf3OYv2DbufQ9jmMnnoq5Ep5hmxh3K3EsZYf5C04qp5kvvnHDOIj9uNYrDvMX7JjTwKfq/LE6H8J18R1M3mH+gl3VFnNxC5uxA3d6wWH+gl3Xh8vxROQz9zGCy/iVqsP8BbuOIVEDXsG8qn0CV/EuRYf5C04phrAK57G1ag/jFN6k5jB/wSnHkFiz2SXGZB/uiZojKYf5C04rhhN8EwnuD2zHg5Qc5i84qdqiFauxB+vqfuQFHqXmMH/BrmM4iKMirxmouz4ucppONWP+rzTduXQA+8T+0tKGvhGRz9xM0WH+gh1juEisiV7Cioa+Gs7ihsmv2eT/StOJYb+oF9Zo3rd4LOqK2xhL3WH+gk0x3CD2KtZjcUPfGC7gtD97hck7zF+wKacZqo4JXoo10nHxP4vRXnOYv2ChUCgUps9vDE1MYMzifHwAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best to use the function colorview and pass in \n",
    "# the transpose of the data used in the input layer\n",
    "colorview(Gray, train_x[:,:,1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first image in our data is labeled 5\n"
     ]
    }
   ],
   "source": [
    "println(\"the first image in our data is labeled \", train_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784-element Array{N0f8,1} with eltype Normed{UInt8,8}:\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " ⋮\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8\n",
       " 0.0N0f8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need a column vector by stacking all the columns of the original matrix\n",
    "reshape(train_x[:,:,1], 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape all of the training data to be a 784 element column\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i = 1:60000\n",
    "    push!(X, reshape(train_x[:,:, i], 784))  # reshape the X to be a single column of size 784\n",
    "    y = zeros(10)\n",
    "    y[train_y[i] + 1] = 1.0                  # create a output layer vector where the correct answer is 1.0\n",
    "    push!(Y, y)\n",
    "end\n",
    "\n",
    "train_data = [x for x in zip(X,Y)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape all of the testing data to be a 784 element column\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i = 1:10000\n",
    "    push!(X, reshape(test_x[:,:, i], 784))  # same as above, just with the training data\n",
    "    y = zeros(10)                           # replaced with the test data\n",
    "    y[test_y[i] + 1] = 1.0\n",
    "    push!(Y, y)\n",
    "end\n",
    "\n",
    "test_data = [x for x in zip(X,Y)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "\n",
    "## Sigmoid function\n",
    "\n",
    "# $$ \\sigma (s) = \\frac{1}{1 + e^{-s}} $$\n",
    "\n",
    "## Pre-activation phase for each layer $l$ for $l = 2, \\ldots , L$ \n",
    "\n",
    "# $$ z^l = W^la^{l-1} + b^l $$\n",
    "\n",
    "## Post-activation phase:\n",
    "\n",
    "# $$ a^l = \\sigma (x^l) $$\n",
    "\n",
    "## Mean Square Error for cost with output layer of n=10:\n",
    "\n",
    "\n",
    "# $$ C = C(W, b) = \\frac{1}{2} \\sum_{k=1}^{n} (a_k^L - y_k^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "σ"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    σ(x)\n",
    "\n",
    "Sigmoid function, used for activation in the neural network\n",
    "# Arguments\n",
    "- `x`: the input argument passed to the function\n",
    "\n",
    "returns\n",
    "- a value between 0 and 1\n",
    "\"\"\"\n",
    "σ(x) = 1.0/(1.0 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip400\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip400)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip401\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip400)\" d=\"\n",
       "M174.862 1486.45 L2352.76 1486.45 L2352.76 47.2441 L174.862 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip402\">\n",
       "    <rect x=\"174\" y=\"47\" width=\"2179\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  236.501,1486.45 236.501,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  750.155,1486.45 750.155,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1263.81,1486.45 1263.81,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1777.46,1486.45 1777.46,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2291.12,1486.45 2291.12,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,1445.78 2352.76,1445.78 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,1106.31 2352.76,1106.31 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,766.846 2352.76,766.846 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,427.38 2352.76,427.38 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip402)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,87.9146 2352.76,87.9146 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1486.45 174.862,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  236.501,1486.45 236.501,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  750.155,1486.45 750.155,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1263.81,1486.45 1263.81,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1777.46,1486.45 1777.46,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2291.12,1486.45 2291.12,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1445.78 200.997,1445.78 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1106.31 200.997,1106.31 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,766.846 200.997,766.846 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,427.38 200.997,427.38 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,87.9146 200.997,87.9146 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip400)\" d=\"M 0 0 M195.262 1523.09 L224.938 1523.09 L224.938 1527.03 L195.262 1527.03 L195.262 1523.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M230.818 1535.98 L238.457 1535.98 L238.457 1509.62 L230.146 1511.29 L230.146 1507.03 L238.41 1505.36 L243.086 1505.36 L243.086 1535.98 L250.725 1535.98 L250.725 1539.92 L230.818 1539.92 L230.818 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M265.794 1508.44 Q262.183 1508.44 260.355 1512 Q258.549 1515.55 258.549 1522.67 Q258.549 1529.78 260.355 1533.35 Q262.183 1536.89 265.794 1536.89 Q269.429 1536.89 271.234 1533.35 Q273.063 1529.78 273.063 1522.67 Q273.063 1515.55 271.234 1512 Q269.429 1508.44 265.794 1508.44 M265.794 1504.73 Q271.605 1504.73 274.66 1509.34 Q277.739 1513.92 277.739 1522.67 Q277.739 1531.4 274.66 1536.01 Q271.605 1540.59 265.794 1540.59 Q259.984 1540.59 256.906 1536.01 Q253.85 1531.4 253.85 1522.67 Q253.85 1513.92 256.906 1509.34 Q259.984 1504.73 265.794 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M722.308 1523.09 L751.983 1523.09 L751.983 1527.03 L722.308 1527.03 L722.308 1523.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M757.099 1505.36 L775.456 1505.36 L775.456 1509.3 L761.382 1509.3 L761.382 1517.77 Q762.4 1517.42 763.419 1517.26 Q764.437 1517.07 765.456 1517.07 Q771.243 1517.07 774.622 1520.24 Q778.002 1523.42 778.002 1528.83 Q778.002 1534.41 774.53 1537.51 Q771.057 1540.59 764.738 1540.59 Q762.562 1540.59 760.294 1540.22 Q758.048 1539.85 755.641 1539.11 L755.641 1534.41 Q757.724 1535.54 759.946 1536.1 Q762.169 1536.66 764.645 1536.66 Q768.65 1536.66 770.988 1534.55 Q773.326 1532.44 773.326 1528.83 Q773.326 1525.22 770.988 1523.11 Q768.65 1521.01 764.645 1521.01 Q762.77 1521.01 760.895 1521.42 Q759.044 1521.84 757.099 1522.72 L757.099 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M1263.81 1508.44 Q1260.2 1508.44 1258.37 1512 Q1256.56 1515.55 1256.56 1522.67 Q1256.56 1529.78 1258.37 1533.35 Q1260.2 1536.89 1263.81 1536.89 Q1267.44 1536.89 1269.25 1533.35 Q1271.08 1529.78 1271.08 1522.67 Q1271.08 1515.55 1269.25 1512 Q1267.44 1508.44 1263.81 1508.44 M1263.81 1504.73 Q1269.62 1504.73 1272.67 1509.34 Q1275.75 1513.92 1275.75 1522.67 Q1275.75 1531.4 1272.67 1536.01 Q1269.62 1540.59 1263.81 1540.59 Q1258 1540.59 1254.92 1536.01 Q1251.86 1531.4 1251.86 1522.67 Q1251.86 1513.92 1254.92 1509.34 Q1258 1504.73 1263.81 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M1767.74 1505.36 L1786.1 1505.36 L1786.1 1509.3 L1772.02 1509.3 L1772.02 1517.77 Q1773.04 1517.42 1774.06 1517.26 Q1775.08 1517.07 1776.1 1517.07 Q1781.88 1517.07 1785.26 1520.24 Q1788.64 1523.42 1788.64 1528.83 Q1788.64 1534.41 1785.17 1537.51 Q1781.7 1540.59 1775.38 1540.59 Q1773.2 1540.59 1770.94 1540.22 Q1768.69 1539.85 1766.28 1539.11 L1766.28 1534.41 Q1768.37 1535.54 1770.59 1536.1 Q1772.81 1536.66 1775.29 1536.66 Q1779.29 1536.66 1781.63 1534.55 Q1783.97 1532.44 1783.97 1528.83 Q1783.97 1525.22 1781.63 1523.11 Q1779.29 1521.01 1775.29 1521.01 Q1773.41 1521.01 1771.54 1521.42 Q1769.69 1521.84 1767.74 1522.72 L1767.74 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M2267.99 1535.98 L2275.63 1535.98 L2275.63 1509.62 L2267.32 1511.29 L2267.32 1507.03 L2275.59 1505.36 L2280.26 1505.36 L2280.26 1535.98 L2287.9 1535.98 L2287.9 1539.92 L2267.99 1539.92 L2267.99 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M2302.97 1508.44 Q2299.36 1508.44 2297.53 1512 Q2295.72 1515.55 2295.72 1522.67 Q2295.72 1529.78 2297.53 1533.35 Q2299.36 1536.89 2302.97 1536.89 Q2306.6 1536.89 2308.41 1533.35 Q2310.24 1529.78 2310.24 1522.67 Q2310.24 1515.55 2308.41 1512 Q2306.6 1508.44 2302.97 1508.44 M2302.97 1504.73 Q2308.78 1504.73 2311.83 1509.34 Q2314.91 1513.92 2314.91 1522.67 Q2314.91 1531.4 2311.83 1536.01 Q2308.78 1540.59 2302.97 1540.59 Q2297.16 1540.59 2294.08 1536.01 Q2291.02 1531.4 2291.02 1522.67 Q2291.02 1513.92 2294.08 1509.34 Q2297.16 1504.73 2302.97 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M74.9365 1431.58 Q71.3254 1431.58 69.4967 1435.14 Q67.6912 1438.68 67.6912 1445.81 Q67.6912 1452.92 69.4967 1456.48 Q71.3254 1460.02 74.9365 1460.02 Q78.5707 1460.02 80.3763 1456.48 Q82.205 1452.92 82.205 1445.81 Q82.205 1438.68 80.3763 1435.14 Q78.5707 1431.58 74.9365 1431.58 M74.9365 1427.87 Q80.7467 1427.87 83.8022 1432.48 Q86.8809 1437.06 86.8809 1445.81 Q86.8809 1454.54 83.8022 1459.15 Q80.7467 1463.73 74.9365 1463.73 Q69.1264 1463.73 66.0477 1459.15 Q62.9921 1454.54 62.9921 1445.81 Q62.9921 1437.06 66.0477 1432.48 Q69.1264 1427.87 74.9365 1427.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M91.9503 1457.18 L96.8345 1457.18 L96.8345 1463.06 L91.9503 1463.06 L91.9503 1457.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M111.904 1431.58 Q108.293 1431.58 106.464 1435.14 Q104.659 1438.68 104.659 1445.81 Q104.659 1452.92 106.464 1456.48 Q108.293 1460.02 111.904 1460.02 Q115.538 1460.02 117.344 1456.48 Q119.172 1452.92 119.172 1445.81 Q119.172 1438.68 117.344 1435.14 Q115.538 1431.58 111.904 1431.58 M111.904 1427.87 Q117.714 1427.87 120.77 1432.48 Q123.848 1437.06 123.848 1445.81 Q123.848 1454.54 120.77 1459.15 Q117.714 1463.73 111.904 1463.73 Q106.094 1463.73 103.015 1459.15 Q99.9595 1454.54 99.9595 1445.81 Q99.9595 1437.06 103.015 1432.48 Q106.094 1427.87 111.904 1427.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M138.918 1431.58 Q135.307 1431.58 133.478 1435.14 Q131.672 1438.68 131.672 1445.81 Q131.672 1452.92 133.478 1456.48 Q135.307 1460.02 138.918 1460.02 Q142.552 1460.02 144.357 1456.48 Q146.186 1452.92 146.186 1445.81 Q146.186 1438.68 144.357 1435.14 Q142.552 1431.58 138.918 1431.58 M138.918 1427.87 Q144.728 1427.87 147.783 1432.48 Q150.862 1437.06 150.862 1445.81 Q150.862 1454.54 147.783 1459.15 Q144.728 1463.73 138.918 1463.73 Q133.107 1463.73 130.029 1459.15 Q126.973 1454.54 126.973 1445.81 Q126.973 1437.06 130.029 1432.48 Q133.107 1427.87 138.918 1427.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M77.5291 1092.11 Q73.918 1092.11 72.0893 1095.68 Q70.2838 1099.22 70.2838 1106.35 Q70.2838 1113.45 72.0893 1117.02 Q73.918 1120.56 77.5291 1120.56 Q81.1633 1120.56 82.9689 1117.02 Q84.7976 1113.45 84.7976 1106.35 Q84.7976 1099.22 82.9689 1095.68 Q81.1633 1092.11 77.5291 1092.11 M77.5291 1088.41 Q83.3392 1088.41 86.3948 1093.01 Q89.4735 1097.6 89.4735 1106.35 Q89.4735 1115.07 86.3948 1119.68 Q83.3392 1124.26 77.5291 1124.26 Q71.7189 1124.26 68.6402 1119.68 Q65.5847 1115.07 65.5847 1106.35 Q65.5847 1097.6 68.6402 1093.01 Q71.7189 1088.41 77.5291 1088.41 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M94.5429 1117.71 L99.4271 1117.71 L99.4271 1123.59 L94.5429 1123.59 L94.5429 1117.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M108.524 1119.66 L124.844 1119.66 L124.844 1123.59 L102.899 1123.59 L102.899 1119.66 Q105.561 1116.9 110.145 1112.27 Q114.751 1107.62 115.932 1106.28 Q118.177 1103.75 119.057 1102.02 Q119.959 1100.26 119.959 1098.57 Q119.959 1095.81 118.015 1094.08 Q116.094 1092.34 112.992 1092.34 Q110.793 1092.34 108.339 1093.11 Q105.909 1093.87 103.131 1095.42 L103.131 1090.7 Q105.955 1089.56 108.409 1088.99 Q110.862 1088.41 112.899 1088.41 Q118.27 1088.41 121.464 1091.09 Q124.658 1093.78 124.658 1098.27 Q124.658 1100.4 123.848 1102.32 Q123.061 1104.22 120.955 1106.81 Q120.376 1107.48 117.274 1110.7 Q114.172 1113.89 108.524 1119.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M129.959 1089.03 L148.316 1089.03 L148.316 1092.97 L134.242 1092.97 L134.242 1101.44 Q135.26 1101.09 136.279 1100.93 Q137.297 1100.74 138.316 1100.74 Q144.103 1100.74 147.482 1103.92 Q150.862 1107.09 150.862 1112.5 Q150.862 1118.08 147.39 1121.18 Q143.918 1124.26 137.598 1124.26 Q135.422 1124.26 133.154 1123.89 Q130.908 1123.52 128.501 1122.78 L128.501 1118.08 Q130.584 1119.22 132.807 1119.77 Q135.029 1120.33 137.506 1120.33 Q141.51 1120.33 143.848 1118.22 Q146.186 1116.11 146.186 1112.5 Q146.186 1108.89 143.848 1106.79 Q141.51 1104.68 137.506 1104.68 Q135.631 1104.68 133.756 1105.1 Q131.904 1105.51 129.959 1106.39 L129.959 1089.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M75.9319 752.645 Q72.3208 752.645 70.4921 756.209 Q68.6865 759.751 68.6865 766.881 Q68.6865 773.987 70.4921 777.552 Q72.3208 781.094 75.9319 781.094 Q79.5661 781.094 81.3717 777.552 Q83.2004 773.987 83.2004 766.881 Q83.2004 759.751 81.3717 756.209 Q79.5661 752.645 75.9319 752.645 M75.9319 748.941 Q81.742 748.941 84.7976 753.547 Q87.8763 758.131 87.8763 766.881 Q87.8763 775.608 84.7976 780.214 Q81.742 784.797 75.9319 784.797 Q70.1217 784.797 67.043 780.214 Q63.9875 775.608 63.9875 766.881 Q63.9875 758.131 67.043 753.547 Q70.1217 748.941 75.9319 748.941 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M92.9457 778.246 L97.8299 778.246 L97.8299 784.126 L92.9457 784.126 L92.9457 778.246 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M102.946 749.566 L121.302 749.566 L121.302 753.501 L107.228 753.501 L107.228 761.973 Q108.247 761.626 109.265 761.464 Q110.284 761.279 111.302 761.279 Q117.089 761.279 120.469 764.45 Q123.848 767.621 123.848 773.038 Q123.848 778.617 120.376 781.719 Q116.904 784.797 110.584 784.797 Q108.409 784.797 106.14 784.427 Q103.895 784.057 101.487 783.316 L101.487 778.617 Q103.571 779.751 105.793 780.307 Q108.015 780.862 110.492 780.862 Q114.496 780.862 116.834 778.756 Q119.172 776.649 119.172 773.038 Q119.172 769.427 116.834 767.321 Q114.496 765.214 110.492 765.214 Q108.617 765.214 106.742 765.631 Q104.89 766.047 102.946 766.927 L102.946 749.566 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M138.918 752.645 Q135.307 752.645 133.478 756.209 Q131.672 759.751 131.672 766.881 Q131.672 773.987 133.478 777.552 Q135.307 781.094 138.918 781.094 Q142.552 781.094 144.357 777.552 Q146.186 773.987 146.186 766.881 Q146.186 759.751 144.357 756.209 Q142.552 752.645 138.918 752.645 M138.918 748.941 Q144.728 748.941 147.783 753.547 Q150.862 758.131 150.862 766.881 Q150.862 775.608 147.783 780.214 Q144.728 784.797 138.918 784.797 Q133.107 784.797 130.029 780.214 Q126.973 775.608 126.973 766.881 Q126.973 758.131 130.029 753.547 Q133.107 748.941 138.918 748.941 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M76.8346 413.179 Q73.2236 413.179 71.3949 416.744 Q69.5893 420.285 69.5893 427.415 Q69.5893 434.521 71.3949 438.086 Q73.2236 441.628 76.8346 441.628 Q80.4689 441.628 82.2744 438.086 Q84.1031 434.521 84.1031 427.415 Q84.1031 420.285 82.2744 416.744 Q80.4689 413.179 76.8346 413.179 M76.8346 409.475 Q82.6448 409.475 85.7003 414.082 Q88.779 418.665 88.779 427.415 Q88.779 436.142 85.7003 440.748 Q82.6448 445.332 76.8346 445.332 Q71.0245 445.332 67.9458 440.748 Q64.8903 436.142 64.8903 427.415 Q64.8903 418.665 67.9458 414.082 Q71.0245 409.475 76.8346 409.475 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M93.8484 438.781 L98.7327 438.781 L98.7327 444.66 L93.8484 444.66 L93.8484 438.781 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M102.622 410.1 L124.844 410.1 L124.844 412.091 L112.297 444.66 L107.413 444.66 L119.219 414.035 L102.622 414.035 L102.622 410.1 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M129.959 410.1 L148.316 410.1 L148.316 414.035 L134.242 414.035 L134.242 422.508 Q135.26 422.16 136.279 421.998 Q137.297 421.813 138.316 421.813 Q144.103 421.813 147.482 424.984 Q150.862 428.156 150.862 433.572 Q150.862 439.151 147.39 442.253 Q143.918 445.332 137.598 445.332 Q135.422 445.332 133.154 444.961 Q130.908 444.591 128.501 443.85 L128.501 439.151 Q130.584 440.285 132.807 440.841 Q135.029 441.396 137.506 441.396 Q141.51 441.396 143.848 439.29 Q146.186 437.183 146.186 433.572 Q146.186 429.961 143.848 427.855 Q141.51 425.748 137.506 425.748 Q135.631 425.748 133.756 426.165 Q131.904 426.582 129.959 427.461 L129.959 410.1 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M66.9736 101.259 L74.6124 101.259 L74.6124 74.8939 L66.3023 76.5605 L66.3023 72.3013 L74.5661 70.6346 L79.242 70.6346 L79.242 101.259 L86.8809 101.259 L86.8809 105.195 L66.9736 105.195 L66.9736 101.259 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M91.9503 99.315 L96.8345 99.315 L96.8345 105.195 L91.9503 105.195 L91.9503 99.315 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M111.904 73.7133 Q108.293 73.7133 106.464 77.2781 Q104.659 80.8198 104.659 87.9494 Q104.659 95.0558 106.464 98.6206 Q108.293 102.162 111.904 102.162 Q115.538 102.162 117.344 98.6206 Q119.172 95.0558 119.172 87.9494 Q119.172 80.8198 117.344 77.2781 Q115.538 73.7133 111.904 73.7133 M111.904 70.0096 Q117.714 70.0096 120.77 74.6161 Q123.848 79.1994 123.848 87.9494 Q123.848 96.6762 120.77 101.283 Q117.714 105.866 111.904 105.866 Q106.094 105.866 103.015 101.283 Q99.9595 96.6762 99.9595 87.9494 Q99.9595 79.1994 103.015 74.6161 Q106.094 70.0096 111.904 70.0096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M138.918 73.7133 Q135.307 73.7133 133.478 77.2781 Q131.672 80.8198 131.672 87.9494 Q131.672 95.0558 133.478 98.6206 Q135.307 102.162 138.918 102.162 Q142.552 102.162 144.357 98.6206 Q146.186 95.0558 146.186 87.9494 Q146.186 80.8198 144.357 77.2781 Q142.552 73.7133 138.918 73.7133 M138.918 70.0096 Q144.728 70.0096 147.783 74.6161 Q150.862 79.1994 150.862 87.9494 Q150.862 96.6762 147.783 101.283 Q144.728 105.866 138.918 105.866 Q133.107 105.866 130.029 101.283 Q126.973 96.6762 126.973 87.9494 Q126.973 79.1994 130.029 74.6161 Q133.107 70.0096 138.918 70.0096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip402)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  236.501,1445.72 256.566,1445.7 442.096,1445.32 553.591,1444.43 647.86,1442.41 750.262,1436.68 844.667,1423.2 895.273,1409.22 945.879,1386.95 975.196,1368.63 \n",
       "  1004.51,1345.04 1033.83,1314.97 1063.14,1277.14 1089.2,1235.98 1115.25,1186.97 1141.3,1129.65 1167.36,1064.05 1213.05,931.253 1258.74,783.596 1308.56,621.28 \n",
       "  1358.37,474.713 1383.43,410.91 1408.48,354.739 1433.54,306.276 1458.6,265.185 1486.3,227.595 1514,197.238 1541.71,173.017 1569.41,153.879 1622.13,128.186 \n",
       "  1674.84,112.312 1784.47,96.4072 1876.75,91.3862 1989.42,89.076 2095.33,88.3291 2265,87.9941 2291.12,87.9763 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip400)\" d=\"\n",
       "M1987.15 216.178 L2280.16 216.178 L2280.16 95.2176 L1987.15 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.15,216.178 2280.16,216.178 2280.16,95.2176 1987.15,95.2176 1987.15,216.178 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip400)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.35,155.698 2156.54,155.698 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip400)\" d=\"M 0 0 M2194.59 175.385 Q2192.78 180.015 2191.07 181.427 Q2189.35 182.839 2186.48 182.839 L2183.08 182.839 L2183.08 179.274 L2185.58 179.274 Q2187.34 179.274 2188.31 178.44 Q2189.29 177.607 2190.47 174.505 L2191.23 172.561 L2180.74 147.052 L2185.26 147.052 L2193.36 167.329 L2201.46 147.052 L2205.97 147.052 L2194.59 175.385 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip400)\" d=\"M 0 0 M2211.85 169.042 L2219.49 169.042 L2219.49 142.677 L2211.18 144.343 L2211.18 140.084 L2219.45 138.418 L2224.12 138.418 L2224.12 169.042 L2231.76 169.042 L2231.76 172.978 L2211.85 172.978 L2211.85 169.042 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(σ,-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dσ"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    dσ(x)\n",
    "\n",
    "Derivative of the Sigmoid function, \n",
    "# Arguments\n",
    "- `x`: the input argument passed to the function\n",
    "\n",
    "returns\n",
    "- a value between 0 and .25 with maximum found at 0\n",
    "\"\"\"\n",
    "dσ(x) = σ(x) * (1-σ(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip440\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip440)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip441\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip440)\" d=\"\n",
       "M174.862 1486.45 L2352.76 1486.45 L2352.76 47.2441 L174.862 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip442\">\n",
       "    <rect x=\"174\" y=\"47\" width=\"2179\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  236.501,1486.45 236.501,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  750.155,1486.45 750.155,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1263.81,1486.45 1263.81,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1777.46,1486.45 1777.46,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2291.12,1486.45 2291.12,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,1445.96 2352.76,1445.96 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,1174.2 2352.76,1174.2 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,902.437 2352.76,902.437 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,630.674 2352.76,630.674 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,358.912 2352.76,358.912 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip442)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  174.862,87.1492 2352.76,87.1492 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1486.45 174.862,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  236.501,1486.45 236.501,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  750.155,1486.45 750.155,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1263.81,1486.45 1263.81,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1777.46,1486.45 1777.46,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2291.12,1486.45 2291.12,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1445.96 200.997,1445.96 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,1174.2 200.997,1174.2 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,902.437 200.997,902.437 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,630.674 200.997,630.674 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,358.912 200.997,358.912 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  174.862,87.1492 200.997,87.1492 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip440)\" d=\"M 0 0 M195.262 1523.09 L224.938 1523.09 L224.938 1527.03 L195.262 1527.03 L195.262 1523.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M230.818 1535.98 L238.457 1535.98 L238.457 1509.62 L230.146 1511.29 L230.146 1507.03 L238.41 1505.36 L243.086 1505.36 L243.086 1535.98 L250.725 1535.98 L250.725 1539.92 L230.818 1539.92 L230.818 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M265.794 1508.44 Q262.183 1508.44 260.355 1512 Q258.549 1515.55 258.549 1522.67 Q258.549 1529.78 260.355 1533.35 Q262.183 1536.89 265.794 1536.89 Q269.429 1536.89 271.234 1533.35 Q273.063 1529.78 273.063 1522.67 Q273.063 1515.55 271.234 1512 Q269.429 1508.44 265.794 1508.44 M265.794 1504.73 Q271.605 1504.73 274.66 1509.34 Q277.739 1513.92 277.739 1522.67 Q277.739 1531.4 274.66 1536.01 Q271.605 1540.59 265.794 1540.59 Q259.984 1540.59 256.906 1536.01 Q253.85 1531.4 253.85 1522.67 Q253.85 1513.92 256.906 1509.34 Q259.984 1504.73 265.794 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M722.308 1523.09 L751.983 1523.09 L751.983 1527.03 L722.308 1527.03 L722.308 1523.09 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M757.099 1505.36 L775.456 1505.36 L775.456 1509.3 L761.382 1509.3 L761.382 1517.77 Q762.4 1517.42 763.419 1517.26 Q764.437 1517.07 765.456 1517.07 Q771.243 1517.07 774.622 1520.24 Q778.002 1523.42 778.002 1528.83 Q778.002 1534.41 774.53 1537.51 Q771.057 1540.59 764.738 1540.59 Q762.562 1540.59 760.294 1540.22 Q758.048 1539.85 755.641 1539.11 L755.641 1534.41 Q757.724 1535.54 759.946 1536.1 Q762.169 1536.66 764.645 1536.66 Q768.65 1536.66 770.988 1534.55 Q773.326 1532.44 773.326 1528.83 Q773.326 1525.22 770.988 1523.11 Q768.65 1521.01 764.645 1521.01 Q762.77 1521.01 760.895 1521.42 Q759.044 1521.84 757.099 1522.72 L757.099 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M1263.81 1508.44 Q1260.2 1508.44 1258.37 1512 Q1256.56 1515.55 1256.56 1522.67 Q1256.56 1529.78 1258.37 1533.35 Q1260.2 1536.89 1263.81 1536.89 Q1267.44 1536.89 1269.25 1533.35 Q1271.08 1529.78 1271.08 1522.67 Q1271.08 1515.55 1269.25 1512 Q1267.44 1508.44 1263.81 1508.44 M1263.81 1504.73 Q1269.62 1504.73 1272.67 1509.34 Q1275.75 1513.92 1275.75 1522.67 Q1275.75 1531.4 1272.67 1536.01 Q1269.62 1540.59 1263.81 1540.59 Q1258 1540.59 1254.92 1536.01 Q1251.86 1531.4 1251.86 1522.67 Q1251.86 1513.92 1254.92 1509.34 Q1258 1504.73 1263.81 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M1767.74 1505.36 L1786.1 1505.36 L1786.1 1509.3 L1772.02 1509.3 L1772.02 1517.77 Q1773.04 1517.42 1774.06 1517.26 Q1775.08 1517.07 1776.1 1517.07 Q1781.88 1517.07 1785.26 1520.24 Q1788.64 1523.42 1788.64 1528.83 Q1788.64 1534.41 1785.17 1537.51 Q1781.7 1540.59 1775.38 1540.59 Q1773.2 1540.59 1770.94 1540.22 Q1768.69 1539.85 1766.28 1539.11 L1766.28 1534.41 Q1768.37 1535.54 1770.59 1536.1 Q1772.81 1536.66 1775.29 1536.66 Q1779.29 1536.66 1781.63 1534.55 Q1783.97 1532.44 1783.97 1528.83 Q1783.97 1525.22 1781.63 1523.11 Q1779.29 1521.01 1775.29 1521.01 Q1773.41 1521.01 1771.54 1521.42 Q1769.69 1521.84 1767.74 1522.72 L1767.74 1505.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M2267.99 1535.98 L2275.63 1535.98 L2275.63 1509.62 L2267.32 1511.29 L2267.32 1507.03 L2275.59 1505.36 L2280.26 1505.36 L2280.26 1535.98 L2287.9 1535.98 L2287.9 1539.92 L2267.99 1539.92 L2267.99 1535.98 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M2302.97 1508.44 Q2299.36 1508.44 2297.53 1512 Q2295.72 1515.55 2295.72 1522.67 Q2295.72 1529.78 2297.53 1533.35 Q2299.36 1536.89 2302.97 1536.89 Q2306.6 1536.89 2308.41 1533.35 Q2310.24 1529.78 2310.24 1522.67 Q2310.24 1515.55 2308.41 1512 Q2306.6 1508.44 2302.97 1508.44 M2302.97 1504.73 Q2308.78 1504.73 2311.83 1509.34 Q2314.91 1513.92 2314.91 1522.67 Q2314.91 1531.4 2311.83 1536.01 Q2308.78 1540.59 2302.97 1540.59 Q2297.16 1540.59 2294.08 1536.01 Q2291.02 1531.4 2291.02 1522.67 Q2291.02 1513.92 2294.08 1509.34 Q2297.16 1504.73 2302.97 1504.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M74.9365 1431.76 Q71.3254 1431.76 69.4967 1435.33 Q67.6912 1438.87 67.6912 1446 Q67.6912 1453.1 69.4967 1456.67 Q71.3254 1460.21 74.9365 1460.21 Q78.5707 1460.21 80.3763 1456.67 Q82.205 1453.1 82.205 1446 Q82.205 1438.87 80.3763 1435.33 Q78.5707 1431.76 74.9365 1431.76 M74.9365 1428.06 Q80.7467 1428.06 83.8022 1432.66 Q86.8809 1437.25 86.8809 1446 Q86.8809 1454.72 83.8022 1459.33 Q80.7467 1463.91 74.9365 1463.91 Q69.1264 1463.91 66.0477 1459.33 Q62.9921 1454.72 62.9921 1446 Q62.9921 1437.25 66.0477 1432.66 Q69.1264 1428.06 74.9365 1428.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M91.9503 1457.36 L96.8345 1457.36 L96.8345 1463.24 L91.9503 1463.24 L91.9503 1457.36 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M111.904 1431.76 Q108.293 1431.76 106.464 1435.33 Q104.659 1438.87 104.659 1446 Q104.659 1453.1 106.464 1456.67 Q108.293 1460.21 111.904 1460.21 Q115.538 1460.21 117.344 1456.67 Q119.172 1453.1 119.172 1446 Q119.172 1438.87 117.344 1435.33 Q115.538 1431.76 111.904 1431.76 M111.904 1428.06 Q117.714 1428.06 120.77 1432.66 Q123.848 1437.25 123.848 1446 Q123.848 1454.72 120.77 1459.33 Q117.714 1463.91 111.904 1463.91 Q106.094 1463.91 103.015 1459.33 Q99.9595 1454.72 99.9595 1446 Q99.9595 1437.25 103.015 1432.66 Q106.094 1428.06 111.904 1428.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M138.918 1431.76 Q135.307 1431.76 133.478 1435.33 Q131.672 1438.87 131.672 1446 Q131.672 1453.1 133.478 1456.67 Q135.307 1460.21 138.918 1460.21 Q142.552 1460.21 144.357 1456.67 Q146.186 1453.1 146.186 1446 Q146.186 1438.87 144.357 1435.33 Q142.552 1431.76 138.918 1431.76 M138.918 1428.06 Q144.728 1428.06 147.783 1432.66 Q150.862 1437.25 150.862 1446 Q150.862 1454.72 147.783 1459.33 Q144.728 1463.91 138.918 1463.91 Q133.107 1463.91 130.029 1459.33 Q126.973 1454.72 126.973 1446 Q126.973 1437.25 130.029 1432.66 Q133.107 1428.06 138.918 1428.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M75.9319 1160 Q72.3208 1160 70.4921 1163.56 Q68.6865 1167.1 68.6865 1174.23 Q68.6865 1181.34 70.4921 1184.91 Q72.3208 1188.45 75.9319 1188.45 Q79.5661 1188.45 81.3717 1184.91 Q83.2004 1181.34 83.2004 1174.23 Q83.2004 1167.1 81.3717 1163.56 Q79.5661 1160 75.9319 1160 M75.9319 1156.29 Q81.742 1156.29 84.7976 1160.9 Q87.8763 1165.48 87.8763 1174.23 Q87.8763 1182.96 84.7976 1187.57 Q81.742 1192.15 75.9319 1192.15 Q70.1217 1192.15 67.043 1187.57 Q63.9875 1182.96 63.9875 1174.23 Q63.9875 1165.48 67.043 1160.9 Q70.1217 1156.29 75.9319 1156.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M92.9457 1185.6 L97.8299 1185.6 L97.8299 1191.48 L92.9457 1191.48 L92.9457 1185.6 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M112.899 1160 Q109.288 1160 107.459 1163.56 Q105.654 1167.1 105.654 1174.23 Q105.654 1181.34 107.459 1184.91 Q109.288 1188.45 112.899 1188.45 Q116.534 1188.45 118.339 1184.91 Q120.168 1181.34 120.168 1174.23 Q120.168 1167.1 118.339 1163.56 Q116.534 1160 112.899 1160 M112.899 1156.29 Q118.709 1156.29 121.765 1160.9 Q124.844 1165.48 124.844 1174.23 Q124.844 1182.96 121.765 1187.57 Q118.709 1192.15 112.899 1192.15 Q107.089 1192.15 104.01 1187.57 Q100.955 1182.96 100.955 1174.23 Q100.955 1165.48 104.01 1160.9 Q107.089 1156.29 112.899 1156.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M129.959 1156.92 L148.316 1156.92 L148.316 1160.85 L134.242 1160.85 L134.242 1169.33 Q135.26 1168.98 136.279 1168.82 Q137.297 1168.63 138.316 1168.63 Q144.103 1168.63 147.482 1171.8 Q150.862 1174.98 150.862 1180.39 Q150.862 1185.97 147.39 1189.07 Q143.918 1192.15 137.598 1192.15 Q135.422 1192.15 133.154 1191.78 Q130.908 1191.41 128.501 1190.67 L128.501 1185.97 Q130.584 1187.1 132.807 1187.66 Q135.029 1188.22 137.506 1188.22 Q141.51 1188.22 143.848 1186.11 Q146.186 1184 146.186 1180.39 Q146.186 1176.78 143.848 1174.67 Q141.51 1172.57 137.506 1172.57 Q135.631 1172.57 133.756 1172.98 Q131.904 1173.4 129.959 1174.28 L129.959 1156.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M76.1634 888.236 Q72.5523 888.236 70.7236 891.801 Q68.918 895.342 68.918 902.472 Q68.918 909.578 70.7236 913.143 Q72.5523 916.685 76.1634 916.685 Q79.7976 916.685 81.6031 913.143 Q83.4318 909.578 83.4318 902.472 Q83.4318 895.342 81.6031 891.801 Q79.7976 888.236 76.1634 888.236 M76.1634 884.532 Q81.9735 884.532 85.029 889.139 Q88.1077 893.722 88.1077 902.472 Q88.1077 911.199 85.029 915.805 Q81.9735 920.388 76.1634 920.388 Q70.3532 920.388 67.2745 915.805 Q64.219 911.199 64.219 902.472 Q64.219 893.722 67.2745 889.139 Q70.3532 884.532 76.1634 884.532 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M93.1771 913.838 L98.0614 913.838 L98.0614 919.717 L93.1771 919.717 L93.1771 913.838 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M103.941 915.782 L111.58 915.782 L111.58 889.416 L103.27 891.083 L103.27 886.824 L111.534 885.157 L116.209 885.157 L116.209 915.782 L123.848 915.782 L123.848 919.717 L103.941 919.717 L103.941 915.782 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M138.918 888.236 Q135.307 888.236 133.478 891.801 Q131.672 895.342 131.672 902.472 Q131.672 909.578 133.478 913.143 Q135.307 916.685 138.918 916.685 Q142.552 916.685 144.357 913.143 Q146.186 909.578 146.186 902.472 Q146.186 895.342 144.357 891.801 Q142.552 888.236 138.918 888.236 M138.918 884.532 Q144.728 884.532 147.783 889.139 Q150.862 893.722 150.862 902.472 Q150.862 911.199 147.783 915.805 Q144.728 920.388 138.918 920.388 Q133.107 920.388 130.029 915.805 Q126.973 911.199 126.973 902.472 Q126.973 893.722 130.029 889.139 Q133.107 884.532 138.918 884.532 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M77.1587 616.473 Q73.5476 616.473 71.7189 620.038 Q69.9134 623.58 69.9134 630.709 Q69.9134 637.816 71.7189 641.38 Q73.5476 644.922 77.1587 644.922 Q80.793 644.922 82.5985 641.38 Q84.4272 637.816 84.4272 630.709 Q84.4272 623.58 82.5985 620.038 Q80.793 616.473 77.1587 616.473 M77.1587 612.769 Q82.9689 612.769 86.0244 617.376 Q89.1031 621.959 89.1031 630.709 Q89.1031 639.436 86.0244 644.042 Q82.9689 648.626 77.1587 648.626 Q71.3486 648.626 68.2699 644.042 Q65.2143 639.436 65.2143 630.709 Q65.2143 621.959 68.2699 617.376 Q71.3486 612.769 77.1587 612.769 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M94.1725 642.075 L99.0567 642.075 L99.0567 647.954 L94.1725 647.954 L94.1725 642.075 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M104.936 644.019 L112.575 644.019 L112.575 617.654 L104.265 619.32 L104.265 615.061 L112.529 613.394 L117.205 613.394 L117.205 644.019 L124.844 644.019 L124.844 647.954 L104.936 647.954 L104.936 644.019 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M129.959 613.394 L148.316 613.394 L148.316 617.33 L134.242 617.33 L134.242 625.802 Q135.26 625.455 136.279 625.293 Q137.297 625.107 138.316 625.107 Q144.103 625.107 147.482 628.279 Q150.862 631.45 150.862 636.867 Q150.862 642.445 147.39 645.547 Q143.918 648.626 137.598 648.626 Q135.422 648.626 133.154 648.255 Q130.908 647.885 128.501 647.144 L128.501 642.445 Q130.584 643.58 132.807 644.135 Q135.029 644.691 137.506 644.691 Q141.51 644.691 143.848 642.584 Q146.186 640.478 146.186 636.867 Q146.186 633.255 143.848 631.149 Q141.51 629.043 137.506 629.043 Q135.631 629.043 133.756 629.459 Q131.904 629.876 129.959 630.755 L129.959 613.394 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M76.5337 344.711 Q72.9226 344.711 71.0939 348.275 Q69.2884 351.817 69.2884 358.947 Q69.2884 366.053 71.0939 369.618 Q72.9226 373.159 76.5337 373.159 Q80.168 373.159 81.9735 369.618 Q83.8022 366.053 83.8022 358.947 Q83.8022 351.817 81.9735 348.275 Q80.168 344.711 76.5337 344.711 M76.5337 341.007 Q82.3439 341.007 85.3994 345.613 Q88.4781 350.197 88.4781 358.947 Q88.4781 367.673 85.3994 372.28 Q82.3439 376.863 76.5337 376.863 Q70.7236 376.863 67.6449 372.28 Q64.5893 367.673 64.5893 358.947 Q64.5893 350.197 67.6449 345.613 Q70.7236 341.007 76.5337 341.007 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M93.5475 370.312 L98.4318 370.312 L98.4318 376.192 L93.5475 376.192 L93.5475 370.312 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M107.529 372.257 L123.848 372.257 L123.848 376.192 L101.904 376.192 L101.904 372.257 Q104.566 369.502 109.149 364.872 Q113.756 360.22 114.936 358.877 Q117.182 356.354 118.061 354.618 Q118.964 352.859 118.964 351.169 Q118.964 348.414 117.02 346.678 Q115.098 344.942 111.996 344.942 Q109.797 344.942 107.344 345.706 Q104.913 346.47 102.135 348.021 L102.135 343.298 Q104.959 342.164 107.413 341.586 Q109.867 341.007 111.904 341.007 Q117.274 341.007 120.469 343.692 Q123.663 346.377 123.663 350.868 Q123.663 352.998 122.853 354.919 Q122.066 356.817 119.959 359.41 Q119.381 360.081 116.279 363.298 Q113.177 366.493 107.529 372.257 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M138.918 344.711 Q135.307 344.711 133.478 348.275 Q131.672 351.817 131.672 358.947 Q131.672 366.053 133.478 369.618 Q135.307 373.159 138.918 373.159 Q142.552 373.159 144.357 369.618 Q146.186 366.053 146.186 358.947 Q146.186 351.817 144.357 348.275 Q142.552 344.711 138.918 344.711 M138.918 341.007 Q144.728 341.007 147.783 345.613 Q150.862 350.197 150.862 358.947 Q150.862 367.673 147.783 372.28 Q144.728 376.863 138.918 376.863 Q133.107 376.863 130.029 372.28 Q126.973 367.673 126.973 358.947 Q126.973 350.197 130.029 345.613 Q133.107 341.007 138.918 341.007 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M77.5291 72.9479 Q73.918 72.9479 72.0893 76.5127 Q70.2838 80.0543 70.2838 87.1839 Q70.2838 94.2903 72.0893 97.8551 Q73.918 101.397 77.5291 101.397 Q81.1633 101.397 82.9689 97.8551 Q84.7976 94.2903 84.7976 87.1839 Q84.7976 80.0543 82.9689 76.5127 Q81.1633 72.9479 77.5291 72.9479 M77.5291 69.2442 Q83.3392 69.2442 86.3948 73.8506 Q89.4735 78.434 89.4735 87.1839 Q89.4735 95.9107 86.3948 100.517 Q83.3392 105.1 77.5291 105.1 Q71.7189 105.1 68.6402 100.517 Q65.5847 95.9107 65.5847 87.1839 Q65.5847 78.434 68.6402 73.8506 Q71.7189 69.2442 77.5291 69.2442 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M94.5429 98.5496 L99.4271 98.5496 L99.4271 104.429 L94.5429 104.429 L94.5429 98.5496 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M108.524 100.494 L124.844 100.494 L124.844 104.429 L102.899 104.429 L102.899 100.494 Q105.561 97.7394 110.145 93.1098 Q114.751 88.457 115.932 87.1145 Q118.177 84.5913 119.057 82.8552 Q119.959 81.096 119.959 79.4062 Q119.959 76.6516 118.015 74.9155 Q116.094 73.1793 112.992 73.1793 Q110.793 73.1793 108.339 73.9432 Q105.909 74.7071 103.131 76.258 L103.131 71.5358 Q105.955 70.4016 108.409 69.8229 Q110.862 69.2442 112.899 69.2442 Q118.27 69.2442 121.464 71.9294 Q124.658 74.6145 124.658 79.1052 Q124.658 81.2349 123.848 83.1561 Q123.061 85.0543 120.955 87.6469 Q120.376 88.3182 117.274 91.5357 Q114.172 94.7302 108.524 100.494 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M129.959 69.8692 L148.316 69.8692 L148.316 73.8043 L134.242 73.8043 L134.242 82.2765 Q135.26 81.9293 136.279 81.7673 Q137.297 81.5821 138.316 81.5821 Q144.103 81.5821 147.482 84.7534 Q150.862 87.9246 150.862 93.3413 Q150.862 98.92 147.39 102.022 Q143.918 105.1 137.598 105.1 Q135.422 105.1 133.154 104.73 Q130.908 104.36 128.501 103.619 L128.501 98.92 Q130.584 100.054 132.807 100.61 Q135.029 101.165 137.506 101.165 Q141.51 101.165 143.848 99.0588 Q146.186 96.9524 146.186 93.3413 Q146.186 89.7302 143.848 87.6237 Q141.51 85.5172 137.506 85.5172 Q135.631 85.5172 133.756 85.9339 Q131.904 86.3506 129.959 87.2302 L129.959 69.8692 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip442)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  236.501,1445.72 256.566,1445.66 442.096,1444.14 553.591,1440.57 647.86,1432.5 699.061,1423.87 750.262,1409.79 797.464,1389.14 844.667,1357.1 869.97,1333.33 \n",
       "  895.273,1303.56 920.576,1266.49 945.879,1220.69 975.196,1154.69 1004.51,1072.64 1019.17,1025.02 1033.83,972.817 1048.49,916.027 1063.14,854.774 1089.2,735.942 \n",
       "  1115.25,607.45 1141.3,475.168 1167.36,347.537 1178.78,295.672 1190.2,247.644 1201.62,204.395 1213.05,166.829 1224.47,135.77 1235.89,111.928 1247.32,95.8676 \n",
       "  1258.74,87.9763 1271.19,88.9027 1283.65,99.7386 1296.1,120.17 1308.56,149.613 1321.01,187.253 1333.46,232.088 1345.92,282.982 1358.37,338.725 1408.48,587.791 \n",
       "  1458.6,829.021 1472.45,888.636 1486.3,944.365 1500.15,996.035 1514,1043.6 1541.71,1126.66 1569.41,1194.75 1595.77,1247.25 1622.13,1289.54 1648.48,1323.3 \n",
       "  1674.84,1350.06 1729.66,1388.87 1784.47,1412.18 1830.61,1424.31 1876.75,1432.1 1989.42,1441.32 2095.33,1444.3 2265,1445.64 2291.12,1445.72 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip440)\" d=\"\n",
       "M1987.15 216.178 L2280.16 216.178 L2280.16 95.2176 L1987.15 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1987.15,216.178 2280.16,216.178 2280.16,95.2176 1987.15,95.2176 1987.15,216.178 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip440)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2011.35,155.698 2156.54,155.698 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip440)\" d=\"M 0 0 M2194.59 175.385 Q2192.78 180.015 2191.07 181.427 Q2189.35 182.839 2186.48 182.839 L2183.08 182.839 L2183.08 179.274 L2185.58 179.274 Q2187.34 179.274 2188.31 178.44 Q2189.29 177.607 2190.47 174.505 L2191.23 172.561 L2180.74 147.052 L2185.26 147.052 L2193.36 167.329 L2201.46 147.052 L2205.97 147.052 L2194.59 175.385 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip440)\" d=\"M 0 0 M2211.85 169.042 L2219.49 169.042 L2219.49 142.677 L2211.18 144.343 L2211.18 140.084 L2219.45 138.418 L2224.12 138.418 L2224.12 169.042 L2231.76 169.042 L2231.76 172.978 L2211.85 172.978 L2211.85 169.042 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(dσ,-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a neual network type\n",
    "# since the data type will need change, it will be mutable\n",
    "mutable struct neural_network\n",
    "    W     # Weight Matrix\n",
    "    b     # Bias matrix\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Neural Network with three types of layers\n",
    "## - Input layer.  The image data.\n",
    "## - Output layer.  Used for the classification of digits.\n",
    "## - Hidden layers.  Multiple layers of neurons used to assist with the classification.\n",
    "\n",
    "![layers](layers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_network"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to form the neural network\n",
    "\"\"\"\n",
    "    create_network(input_layer_size, hidden_layer_sizes, output_layer_size)\n",
    "\n",
    "Creates a neural network based on values in the arguemnts to the function \n",
    "# Arguments\n",
    "- `input_layer_size`   : the size of the input layer\n",
    "- `hidden_layer_sizes` : an array of sizes of the hidden layers\n",
    "- `output_layer_size`  : the size of the output layer\n",
    "\n",
    "returns\n",
    "- a neural network initiliazed with random values with the sizes specified\n",
    "\"\"\"\n",
    "function create_network(input_layer_size, hidden_layer_sizes, output_layer_size)\n",
    "    \n",
    "    W = [[0.0], randn(hidden_layer_sizes[1], input_layer_size)]\n",
    "    \n",
    "    b = [[0.0], randn(hidden_layer_sizes[1])]\n",
    "    \n",
    "    # construct the hidden layers\n",
    "    for i = 2:length(hidden_layer_sizes)\n",
    "        push!(W, randn(hidden_layer_sizes[i], hidden_layer_sizes[i-1]))\n",
    "        push!(b, rand(hidden_layer_sizes[i]))\n",
    "    end\n",
    "    \n",
    "    # final, output layer\n",
    "    push!(W, randn(output_layer_size, hidden_layer_sizes[end]))\n",
    "    push!(b, randn(output_layer_size))\n",
    "    \n",
    "    # retrun the neural network type and use the W and b as input and this is returned\n",
    "    # as the output of hte create_network function\n",
    "    return neural_network(W, b)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network(Array{Float64,N} where N[[0.0], [1.13135962818687 0.758082059409886 … -0.4281697116904303 1.3680202757181805; -0.02133405282399775 1.6922823236941837 … 0.49776094863023707 -0.4194499806917455; … ; 0.16532457027123915 -1.172476102931094 … -0.6231185821720737 0.22132918748986544; -0.5157870094392545 0.0620252039516046 … -1.6969865116989153 0.892597804616782], [0.1980193142108844 0.23958735241679213 … -0.29600158467604837 -0.40354617616903876; -0.748114132936791 -0.8720018058712032 … 0.6275784661787498 -0.08772262498960086; … ; 0.4354438492600971 -0.814682696230068 … -0.6682231007058432 0.8322052291576062; 0.5712280881528602 -1.3137937504694748 … 0.1739819935643854 -0.32029162732821786], [0.38576057203719927 0.14714908889160544 … -0.8278861688612018 0.21458157019943888; -0.5604510684555573 0.9808574847102611 … -0.6400262751752988 -0.3397471619686875; … ; 0.24120706360379265 -0.30205842787752807 … 0.5041100321516674 0.17465696910323045; 0.3115184057272767 0.845899567363968 … 0.7018648886586253 0.49698018839562447], [1.1712720990340197 1.9684570998239759 … -1.6720070617263556 -1.1783478892574322; 0.2454133555729397 -0.34095267714878635 … 0.5757329131360636 0.7851108792365411; … ; -0.6998329063372314 1.8651831980462268 … 1.0128338488479305 0.9006010351342043; 0.7603452080648759 -0.13876358062069422 … -0.7466939524677308 -0.08880923208847526]], [[0.0], [-0.6741975366299958, 1.8289533449025248, -0.819210385064617, -0.13749626566083736, 0.18685655013924352, -1.229721779028793, -0.1928337091989821, -0.33888667460320493, 1.362280654244017, -0.6378266134329089  …  0.8461488409839888, 0.16987247095619376, 2.237379465342072, -0.9489769885798833, 0.595435859781817, 0.506863926793024, -0.3474546413959295, -0.8373715504323587, -1.7828625042888184, 0.10255571271064429], [0.8286228991259463, 0.7666307175635596, 0.8736001316950366, 0.6629509559516744, 0.7584326733896354, 0.1987670776566146, 0.1375005202996784, 0.917344611042157, 0.9303945622727461, 0.6006253616409682  …  0.5433715705065087, 0.6241219167813006, 0.49291391544295315, 0.07625132587507721, 0.29487487954376523, 0.15670786976078754, 0.0861917426050125, 0.9751981512411254, 0.9269092653495947, 0.7221895242632819], [0.5441958962567373, 0.13355090251205404, 0.13829888611789154, 0.06410452236469344, 0.17782864255792852, 0.8073333026394474, 0.10793758487987914, 0.581489036616754, 0.6318075615989633, 0.19927672619249703  …  0.42089160559409855, 0.09212890718279265, 0.7315313529309919, 0.6016530834639717, 0.4717251175536761, 0.5588513470552099, 0.22137102358117566, 0.24883022505323704, 0.7350266021568923, 0.18219759998410656], [-0.45017604161885233, -0.6646256962474256, -2.351988532007916, 1.0838310983751105, 0.623916822175114, -0.7057010425388369, 0.6936616247468879, 0.4286578170459751, -0.6243683757532077, -0.6103490676117205]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 784 is the input layer, which is the size of the image data when column stacked\n",
    "# 100,100,100 are the hidden layers\n",
    "# 10 is the size of the ouput layer, the ten digit possiblities\n",
    "\n",
    "NN = create_network(784, [100, 100, 100], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Array{Float64,N} where N,1}:\n",
       " [0.0]\n",
       " [1.13135962818687 0.758082059409886 … -0.4281697116904303 1.3680202757181805; -0.02133405282399775 1.6922823236941837 … 0.49776094863023707 -0.4194499806917455; … ; 0.16532457027123915 -1.172476102931094 … -0.6231185821720737 0.22132918748986544; -0.5157870094392545 0.0620252039516046 … -1.6969865116989153 0.892597804616782]\n",
       " [0.1980193142108844 0.23958735241679213 … -0.29600158467604837 -0.40354617616903876; -0.748114132936791 -0.8720018058712032 … 0.6275784661787498 -0.08772262498960086; … ; 0.4354438492600971 -0.814682696230068 … -0.6682231007058432 0.8322052291576062; 0.5712280881528602 -1.3137937504694748 … 0.1739819935643854 -0.32029162732821786]\n",
       " [0.38576057203719927 0.14714908889160544 … -0.8278861688612018 0.21458157019943888; -0.5604510684555573 0.9808574847102611 … -0.6400262751752988 -0.3397471619686875; … ; 0.24120706360379265 -0.30205842787752807 … 0.5041100321516674 0.17465696910323045; 0.3115184057272767 0.845899567363968 … 0.7018648886586253 0.49698018839562447]\n",
       " [1.1712720990340197 1.9684570998239759 … -1.6720070617263556 -1.1783478892574322; 0.2454133555729397 -0.34095267714878635 … 0.5757329131360636 0.7851108792365411; … ; -0.6998329063372314 1.8651831980462268 … 1.0128338488479305 0.9006010351342043; 0.7603452080648759 -0.13876358062069422 … -0.7466939524677308 -0.08880923208847526]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial (random) weights\n",
    "NN.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Array{Float64,1},1}:\n",
       " [0.0]\n",
       " [-0.6741975366299958, 1.8289533449025248, -0.819210385064617, -0.13749626566083736, 0.18685655013924352, -1.229721779028793, -0.1928337091989821, -0.33888667460320493, 1.362280654244017, -0.6378266134329089  …  0.8461488409839888, 0.16987247095619376, 2.237379465342072, -0.9489769885798833, 0.595435859781817, 0.506863926793024, -0.3474546413959295, -0.8373715504323587, -1.7828625042888184, 0.10255571271064429]\n",
       " [0.8286228991259463, 0.7666307175635596, 0.8736001316950366, 0.6629509559516744, 0.7584326733896354, 0.1987670776566146, 0.1375005202996784, 0.917344611042157, 0.9303945622727461, 0.6006253616409682  …  0.5433715705065087, 0.6241219167813006, 0.49291391544295315, 0.07625132587507721, 0.29487487954376523, 0.15670786976078754, 0.0861917426050125, 0.9751981512411254, 0.9269092653495947, 0.7221895242632819]\n",
       " [0.5441958962567373, 0.13355090251205404, 0.13829888611789154, 0.06410452236469344, 0.17782864255792852, 0.8073333026394474, 0.10793758487987914, 0.581489036616754, 0.6318075615989633, 0.19927672619249703  …  0.42089160559409855, 0.09212890718279265, 0.7315313529309919, 0.6016530834639717, 0.4717251175536761, 0.5588513470552099, 0.22137102358117566, 0.24883022505323704, 0.7350266021568923, 0.18219759998410656]\n",
       " [-0.45017604161885233, -0.6646256962474256, -2.351988532007916, 1.0838310983751105, 0.623916822175114, -0.7057010425388369, 0.6936616247468879, 0.4286578170459751, -0.6243683757532077, -0.6103490676117205]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial (random) biases\n",
    "NN.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "\n",
      "(100, 784)\n",
      "\n",
      "(100, 100)\n",
      "\n",
      "(100, 100)\n",
      "\n",
      "(10, 100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect the size of the layers by interating through the 3 dimensional matrix of weights\n",
    "for w in NN.W\n",
    "        println(size(w))\n",
    "        println(\"\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward_pass (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    forward_pass(network, training_instance)\n",
    "\n",
    "Compute the pre-activationa nd post-activation at each layer\n",
    "# Arguments\n",
    "- `network`   : a neural netowrk\n",
    "- `training_instance` : a single instance for training\n",
    "                        a tuple with one entry is the feature that we need to pass in\n",
    "\n",
    "returns\n",
    "- a neural network initiliazed with random values with the sizes specified\n",
    "\"\"\"\n",
    "\n",
    "function forward_pass(network, training_instance)\n",
    "    Z = [[0.0]]                   # preactivation\n",
    "    A = [training_instance[1]]    # post activation, the training instance\n",
    "    \n",
    "    for i = 2:length(network.W)   # how many layers there are\n",
    "        # push into our preactivation \n",
    "        push!(Z, network.W[i]*A[i-1] + network.b[i])\n",
    "        # push into our post activation, brodcast, or apply signoid to each\n",
    "        push!(A, σ.(Z[i]))\n",
    "    end\n",
    "    # return Z and A, which contain the pre and post activation at each layer\n",
    "    return Z, A\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    predict(network, training_instance)\n",
    "\n",
    "Compute the pre-activationa nd post-activation at each layer\n",
    "# Arguments\n",
    "- `network`           : a neural netowrk\n",
    "- `training_instance` : a single instance for training\n",
    "                        a tuple with one entry is the feature that we need to pass in\n",
    "\n",
    "returns\n",
    "- the prediction of the network, which digit it recognizes based on the instance\n",
    "\"\"\"\n",
    "\n",
    "function predict(network, training_instance)\n",
    "    Z, A = forward_pass(network, training_instance)\n",
    "    # return the index of the highest valued element in the array, subtracted by 1\n",
    "    # because Julia is 1 index and not 0, zero is in the 1 index\n",
    "    return argmax(A[end]) + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success_percentage (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    predict(network, training_instance)\n",
    "\n",
    "Compute the pre-activationa nd post-activation at each layer\n",
    "# Arguments\n",
    "- `network`           : a neural netowrk\n",
    "- `data_set`          : the data set that is being used to test the network\n",
    "\n",
    "returns\n",
    "- a string with the calculation of percentage accuracy\n",
    "\"\"\"\n",
    "\n",
    "function success_percentage(network, data_set)\n",
    "    return string(\"The percentages of correctly classified images is  \", \n",
    "    sum([predict(network, x) == argmax(x[2]) - 1 ? 1 : 0 for x in data_set])/length(data_set)*100, '%')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The percentages of correctly classified images is  8.08%\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the current success with the random weights\n",
    "success_percentage(NN, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error_deltas (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    error_deltas(network, training_instance)\n",
    "\n",
    "Compute the output error and the hidden layer error at each layer\n",
    "# Arguments\n",
    "- `network`           : a neural netowrk type\n",
    "- `training_instance` : a single instance for training\n",
    "                        a tuple with one entry is the feature \n",
    "\n",
    "returns\n",
    "- The error deltas\n",
    "\"\"\"\n",
    "\n",
    "function error_deltas(network, training_instance)\n",
    "    L = size(network.W)[1]\n",
    "    Z, A = forward_pass(network, training_instance)      # used to calculate the pre and post activation at each layer\n",
    "    δ = [(A[end] - training_instance[2]).*dσ.(Z[end])]   #Chronicer product of the deriviate of the cost wrt to A times the dreivateve of Z at the last layer\n",
    "    for i = L-1:-1:2\n",
    "        pushfirst!(δ, (network.W[i+1]'*δ[1]).*dσ.(Z[i]))\n",
    "    end\n",
    "    pushfirst!(δ, [0.0])\n",
    "    return A, δ\n",
    "end     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array{Normed{UInt8,8},1}[[0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8  …  0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8, 0.0N0f8], [0.992N0f8, 0.957N0f8, 0.004N0f8, 1.0N0f8, 0.0N0f8, 0.059N0f8, 0.004N0f8, 0.016N0f8, 0.769N0f8, 0.012N0f8  …  0.0N0f8, 0.533N0f8, 1.0N0f8, 0.0N0f8, 0.902N0f8, 0.922N0f8, 0.941N0f8, 0.012N0f8, 1.0N0f8, 0.792N0f8], [0.725N0f8, 0.992N0f8, 0.918N0f8, 1.0N0f8, 0.0N0f8, 0.0N0f8, 0.988N0f8, 0.008N0f8, 0.016N0f8, 0.796N0f8  …  0.996N0f8, 0.0N0f8, 1.0N0f8, 0.788N0f8, 1.0N0f8, 0.004N0f8, 0.565N0f8, 1.0N0f8, 0.996N0f8, 0.957N0f8], [0.996N0f8, 0.408N0f8, 0.451N0f8, 0.525N0f8, 1.0N0f8, 1.0N0f8, 0.929N0f8, 1.0N0f8, 0.561N0f8, 0.0N0f8  …  0.0N0f8, 0.0N0f8, 0.004N0f8, 1.0N0f8, 0.996N0f8, 0.165N0f8, 0.02N0f8, 1.0N0f8, 0.0N0f8, 0.012N0f8], [0.902N0f8, 0.925N0f8, 1.0N0f8, 0.953N0f8, 1.0N0f8, 0.969N0f8, 0.071N0f8, 1.0N0f8, 0.141N0f8, 1.0N0f8]], [[0.0], [-0.0004947897342521276, -0.0034823652721773938, -0.000550781689744682, -2.068917543248134e-5, -3.1393641125135665e-6, -0.006007612708713423, -0.0007246749246003466, 0.000778537515621623, 0.017148013756728028, -0.002029388599248866  …  -4.92128976869481e-8, -0.038275300658836796, -7.356008632367105e-8, 2.4131547092739845e-5, 0.005154708706669751, 0.008614803499904813, -0.0018978387190716766, 0.0011845685108413234, 2.0310545810730753e-5, 5.05533604213395e-6], [-0.03228612663423339, 0.00023254344170301969, -0.012703968032450531, 8.236831405391186e-5, -2.7914999308917246e-5, -4.267882327198988e-6, 0.00041292902635183345, 6.989202099568472e-5, 0.00014337967916512319, 0.013735345164084655  …  -0.0003376295818963794, 5.9308124768865224e-5, -1.0096860920295591e-6, 0.009485734955347751, -4.969154791992735e-9, 0.00010315195460558118, -0.01386179437434482, 0.00019573686867719605, 0.00019299271387497398, 0.0028835954429924566], [0.000569879835760394, 0.04871377004977587, -0.0015351117860202973, 0.01684791126494559, 7.958079634749896e-5, 3.438985474503942e-8, 0.000732721047490451, -3.100264254561789e-5, 0.056811658087138873, -0.00013990568969463567  …  1.0649862858052934e-6, -8.885245621589837e-5, 0.0002854418471843419, -1.9122482022671197e-7, 0.0006200068366223641, -0.02028525812110262, -0.0024055044527867284, -3.269257280916388e-6, -5.930423334884503e-5, -0.00011272961707898909], [0.07903339685882614, 0.06464913333932615, 0.00022245230517104904, 0.041426848362391154, 0.0007688694692168247, -0.0009539706896855553, 0.004581330180512124, 8.346187323069193e-5, 0.0169621863309577, 0.0013447687500854778]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_test, δ_test = error_deltas(NN, train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       "  0.07903339685882614\n",
       "  0.06464913333932615\n",
       "  0.00022245230517104904\n",
       "  0.041426848362391154\n",
       "  0.0007688694692168247\n",
       " -0.0009539706896855553\n",
       "  0.004581330180512124\n",
       "  8.346187323069193e-5\n",
       "  0.0169621863309577\n",
       "  0.0013447687500854778"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "δ_test[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_random_mini_batch (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    make_random_mini_batch(mini_batch_size, data_set)\n",
    "\n",
    "Creates a small batch of examples from the data set\n",
    "# Arguments\n",
    "- `mini_batch_size`   : the size of the mini batch, number of entries\n",
    "- `data_set`          : the complete data set where the subset will be taken from\n",
    "\n",
    "returns\n",
    "- The subset of data_set of size mini_batch_size\n",
    "\"\"\"\n",
    "\n",
    "function  make_random_mini_batch(mini_batch_size, data_set)\n",
    "    k = rand(1:size(data_set)[1] - mini_batch_size)\n",
    "    return data_set[k:k + mini_batch_size]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mini_batch_update! (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    mini_batch_update!(network::neural_network, mini_batch_size::Int64, data_set, α::Float64)\n",
    "\n",
    "Updates the network based using stochastic gradient descenet with small batches\n",
    "# Arguments\n",
    "- `network`           : the neural network, a combination of weights and biases\n",
    "- `data_set`          : the complete data set of features and labels\n",
    "- `mini_batch_size`   : the size of the mini batch, number of entries\n",
    "- `α`                 : the learning rate of the algorithm\n",
    "\n",
    "returns\n",
    "- nothing, the network itself is updated\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "function mini_batch_update!(network::neural_network, mini_batch_size::Int64, data_set, α::Float64)\n",
    "    mini_batch = make_random_mini_batch(mini_batch_size, data_set)\n",
    "    L = size(network.W)[1]\n",
    "    A, δ = error_deltas(NN, mini_batch[1])\n",
    "    A_batch = []\n",
    "    δ_batch = []\n",
    "    push!(A_batch, A)\n",
    "    push!(δ_batch, δ)\n",
    "    \n",
    "    for i = 2:mini_batch_size\n",
    "        A, δ = error_deltas(NN, mini_batch[i])\n",
    "        push!(A_batch, A)\n",
    "        push!(δ_batch, δ)\n",
    "    end\n",
    "    \n",
    "    for l = L:-1:2\n",
    "        network.W[l] -= (α/mini_batch_size)*sum([δ_batch[i][l]*A_batch[i][l-1]' for i = 1:mini_batch_size])\n",
    "        network.b[l] -= (α/mini_batch_size)*sum([δ_batch[i][l]                  for i = 1:mini_batch_size])\n",
    "    end\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ = 1:100\n",
    "    mini_batch_update!(NN, 2, train_data, 0.4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The percentages of correctly classified images is  8.99%\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_percentage(NN, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ = 1:100000   # increase the number of iterations of training to hopefully improve success percentages\n",
    "    mini_batch_update!(NN, 2, train_data, 0.4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The percentages of correctly classified images is  1.0%\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_percentage(NN, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_test_img (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    show_test_img(i)\n",
    "\n",
    "displays a image from the test data set\n",
    "# Arguments\n",
    "- `i`           : index of the entry to be displayed\n",
    "\n",
    "\n",
    "returns\n",
    "- nothing, just displays the image in grayscale after being transposed\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "function show_test_img(i)\n",
    "    colorview(Gray, test_x[:,:,i]')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_test_example"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    show_test_example(network::neural_network, i::Int64, testing_data)\n",
    "\n",
    "displays a image from the test data set along with both the the prediction and correct label\n",
    "# Arguments\n",
    "- `i`           : index of the entry to be displayed\n",
    "\n",
    "\n",
    "returns\n",
    "- nothing, just displays the image in grayscale after being transposed\n",
    "\"\"\"\n",
    "function show_test_example(network::neural_network, i::Int64, testing_data)\n",
    "    println(\"Predicted Label: \", predict(network, testing_data[i]))\n",
    "    println(\"Actual Label: \", argmax(testing_data[i][2])-1)\n",
    "    show_test_img(i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 2\n",
      "Actual Label: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIzSURBVGje7dlNiE9RGAbwnxnyMUU+aibDQqjZYeVrMxs2pCyFlBSxUWLjMxaSlY1kgdigrCxMiTILiSnKRrYkX4WN8lFjce4/996Z/50r5X+c7lO37nnve+5zn57OPee8hwYNGjRo0KBBg/8fk/60Qw/2YwaO4Dx2Z89e4TiuVPTv+tcK0yecXDdxKtbgFmZlsYcYwGjWXoBjgr8X8TMGhekT1h6HW3G1FNuHZ4KPfTgs+Aer8CQGhekT1vJwEDcxtxTvLrUvYUd2fxm7YlCYPuGE/9JB3FD07w2ujZN7DpsxE+sxG586rTB9wspx2IM7WJuLvcZGPG/TZziX34+3nVaYPmHlOJyv6B9s0d6/KBWmT1jp4Z5xYu8r8vvQG5vC9Anbetir6OF9bMfHipctxZLYFKZP2NbDLkzLtb8ZO7eVcSB3vxfvYlCYPmHlvzS/4PkxwVevxqZc7J7fe/+OKkyfsNLDlgffcboib5mwHm3lP8WHWBSmT1ir1vY4u8bDIlzPtb/iLL7EojB9wloeDmTXi1J8pbDXX5yLPRBqAtEoTJ+wlofzsELRw4M4ozjnDeFEbArTJ2xbp5kj1LP7s/YI1gl1tJ04KtRLWx4OYZuxtbWOK0yfsLLWdkhxLfMS07Ew13lUODdcjs8xKkyfsNLDXlxQ3DOUOz8SfL4dq8L0CSc8e5qCU8L8V8YwNghr0WgVpk9Y6/ywWxhrrTrMCO7ipLB3jFph+oQNGjRo0ODv8Qu+vU8qKd4vBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = rand([x for x = 1:10000])\n",
    "show_test_example(NN, i, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 11\n",
      "Actual Label: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIcSURBVGje7dnPi05RGAfwjx8xpjQ1SiFeZWXCirBTs7CwYUUWLEiykLAgCxs7UspvFpIfi6EoC9Es5A+QKRtEpJhEpCg1vRbnTvM23l+Xmve8p/Pd3HOfe8799u3bc5/znEtGRkZGRkZGRkZGRsb/Y1rZBUuxB0dRLWLfcBDX2lg/faoVpk/Ylodz0Yft2I8FxcJqzZzv6MdaPMPvWBSmTziz1YQKnmBxTewdngseDmMZNmM5HuEYzsaiMH3Cunm4C48xiovYKfj1AVdwC29q5s/AHMHP1UIODuBtDArTJ6ybhw8E/w5hRxG7iQP4Wmf+GDZgjeD1LKySPZwi1PVwtLiuEBL1ME43eME89Ar5OZ7Ul3E/FoXpEzath5twXGP/egWvFmG+kINjuBeTwvQJW+5phhvEK9iK9ZPip/AwJoXpEzbtLV7hC4bQgy1YgpdCvesR9jPjGMGg+jWzYwrTJ2zq4W5c8ncvqEFsoYlaGo3C9Ambfkuv4hOO4Bdu1zwbwR0hL3/ihNb+dURh+oSlz9rGcQ57i/EQtsWqMH3Cf/KwIvR+VXzERryIVWH6hC33pZMxWzinIfQRJ7XvX0cUpk9Y2sMzWFeMbxT3UStMn7D0t/SzcDbzAyvxPnaF6ROWysNB4R9UVdirlvWvIwrTJyzl4YCJnv5CtyhMn7CUh30143043w0K0ycsVQ/78RpPcR13u0Fh+oQZ3Y8/MMlVTt3dPdYAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = rand([x for x = 1:10000])\n",
    "show_test_example(NN, i, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 4\n",
      "Actual Label: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAG2SURBVGje7dkxaxRRFMXxX0RCbAImkICN2EZiAiksLIIIViltrAUL6yD4KRQk+QApkiZh0wQJKQQbUxlIoYWWgkhAFtMIwWgxC7vEmd0Jbpzn5R2YYu57M3/OHO68NwxZWVlZWVlZI4Mm3MFMz/kCHncu/NWp7WAVr2oAL/1rh/GBlRnO4RkWMVXjRm+xhHZqDuMDKzM81e2zumrhQWoO4wOHmmEbk6k5jA+8XGfSd3zBJvZ66i1cTd1hfGBlhk91+/C98v3Kyf/gMD5w4L60SrN4g/GeWlt+l6bUh/00o3iPjp+pv0jRYXzguTOcVeR340z9k2K9TM5hfOC5MryJXUyXjLXwIUWH8YG1M5zAE3/md4ojvEzVYXxgrQxvYRvXS8aOcC1lh/GBtTJ8qDq/R6k7jA8c+G1xBd8wWjK2pPhuHOscZTrGzyYdxgf27cMpbCnPD24r9jn3cL9iznOs4bAph/GBfftwDu+GAPmqu2bGf6Rp9eGwNNGkw/jAC89wAytNOowP/OsMT3DQc76LecW//X18xI8mHcYH9s3wM17jbsX4smKtW0/ZYXxgVlZWVlZWFr8Ba7059HnNBCQAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = rand([x for x = 1:10000])\n",
    "show_test_example(NN, i, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 9\n",
      "Actual Label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAHfSURBVGje7dm7axRRFMfxjzGl4AsLC7WxFB9YSdBOVxtR0EItLCzEQlJYWYo2VqIo2lhrJ0FRohGxsAiID/wbBBFiYRQfEGJxL2RZspPJRpKZw/01e8/dO/z48uPMnGEoKioqKioqKioqKipaulYNctF2nOqqz2AjbuExPlRcO7TchPENa2W4E0cwKmU1hGHMznN2Bj9wEG+bQBjfcLjOoTFs69mb7XN2NdZiRMlwmVSrDy/iZs/eI3zJ66+4jbs4kfee4GgTCOMb1urD+1IffsbDvDeFv11n1mFLV/2yKYTxDQeaaXq1Hg9wKNd/cAzjTSCMb1irD6t0AJfN5fcb58yf34oQxjdcUoYjuIE9uX6Hj1JPNoYwvuHA99LTuIc1uZ6Q3hmnmkYY33DRfbgJd9CR8puWZtBRC+e3IoTxDRfVh2dxCTtyPY3z5mbVRhLGN6yd4S7pXX9rrp/iKiabThjfsFaGG/AJm/EdL6T++9YGwviGCz4PO7gm5QcXVM+djSOMb1iZ4WFcwd5cT+JZ2wjjG1beS19jf14/x3W8ahthfMO+fdjBvryewElpDm0dYXzDvhnuzn++wXH8bCthfMO+Gc7k3/f+X34rQhjfsPJ5OC59f/jVZsL4hkXt1z/kxUHzYFIVKQAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 reinterpret(Gray{N0f8}, ::LinearAlgebra.Adjoint{Normed{UInt8,8},Array{Normed{UInt8,8},2}}):\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = rand([x for x = 1:10000])\n",
    "show_test_example(NN, i, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
